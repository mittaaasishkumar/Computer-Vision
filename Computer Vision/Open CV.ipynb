{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e18d556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\mitta aasish kumar\\anaconda3\\lib\\site-packages (4.9.0.80)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\mitta aasish kumar\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622d98a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement opencv--upgrade (from versions: none)\n",
      "ERROR: No matching distribution found for opencv--upgrade\n"
     ]
    }
   ],
   "source": [
    "pip install opencv--upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "040c849d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.9.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a735aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021150e6",
   "metadata": {},
   "source": [
    "### Load/Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4643c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image using 'imread' specifying the path to image\n",
    "img=cv2.imread('image_examples/Modi.jpg',0)    #1-Color,  0-B/W\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c87b95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "cv2.imshow('Modi',img)  #Modi---name on the display\n",
    "cv2.waitKey()    ##Means waits until we close,we can give time also in brackets\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8505d",
   "metadata": {},
   "source": [
    "### Let's take a closer look at how images are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ab9b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "##prints pixels of the image   B/W -->2D, Colour-->3D\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abfdae71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d37a15d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aefde115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1358, 1500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa8185d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mitta Aasish Kumar\\\\Data Science Course\\\\Artificial Intelligence\\\\Computer Vision'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba83981",
   "metadata": {},
   "source": [
    "## Resize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5eb799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(r'C:\\Users\\Mitta Aasish Kumar\\Data Science Course\\Artificial Intelligence\\Computer Vision\\image_examples\\Modi.jpg',1)\n",
    "\n",
    "resized_image=cv2.resize(img,(750,679))  #resizing to 50%,Color Image\n",
    "\n",
    "gray=cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY) #B & W\n",
    "\n",
    "cv2.imshow('Modi Image',img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf77290",
   "metadata": {},
   "source": [
    "## Save Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ed3915f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Saves in same directory\n",
    "cv2.imwrite('pm_resize.jpg',resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e23918",
   "metadata": {},
   "source": [
    "## Face Detection using HAAR Cascade Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f4f40a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[276 128 301 301]]\n"
     ]
    }
   ],
   "source": [
    "#Load the face features\n",
    "face_classifier=cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "#Load the image\n",
    "image=cv2.imread(r'C:\\Users\\Mitta Aasish Kumar\\Data Science Course\\Artificial Intelligence\\Computer Vision\\image_examples\\Modi.jpg',1)\n",
    "\n",
    "resized_image=cv2.resize(image,(679,750))\n",
    "\n",
    "gray=cv2.cvtColor(resized_image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces=face_classifier.detectMultiScale(gray,1.05,5)   #Image tuning\n",
    "\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4104bd0",
   "metadata": {},
   "source": [
    "- For increasing accuracy reduce zoom size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e7964de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:10: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Mitta Aasish Kumar\\AppData\\Local\\Temp\\ipykernel_21668\\1128125491.py:10: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "face_classifier=cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "image=cv2.imread(r'C:\\Users\\Mitta Aasish Kumar\\Data Science Course\\Artificial Intelligence\\Computer Vision\\image_examples\\Modi.jpg',1)\n",
    "\n",
    "image=cv2.resize(image,(679,750))\n",
    "\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces=face_classifier.detectMultiScale(gray,1.01,5)\n",
    "\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "else:\n",
    "    for(x,y,l,b) in faces:\n",
    "        cv2.rectangle(image, (x,y), (x+1,y+b), (0,255,0),1)\n",
    "        \n",
    "cv2.imshow('Face Detection',image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18feb368",
   "metadata": {},
   "source": [
    "## Face & Eye detectionusing HAAR Cascade Classifiers in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c6c2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96e976a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Mitta Aasish Kumar\\AppData\\Local\\Temp\\ipykernel_21668\\3304464233.py:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "face_classifier=cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "eye_classifier=cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img=cv2.imread(r'C:\\Users\\Mitta Aasish Kumar\\Data Science Course\\Artificial Intelligence\\Computer Vision\\image_examples\\Modi.jpg',1)\n",
    "\n",
    "resized_image=cv2.resize(image,(500,500))\n",
    "\n",
    "gray=cv2.cvtColor(resized_image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces=face_classifier.detectMultiScale(gray,1.03,5)\n",
    "\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "    \n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(resized_image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray=gray[y:y+h,x:x+w]\n",
    "    roi_color=resized_image[y:y+h,x:x+w]\n",
    "    eyes=eye_classifier.detectMultiScale(roi_gray)\n",
    "    for(ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),1)\n",
    "        \n",
    "cv2.imshow('img',resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fc0ff",
   "metadata": {},
   "source": [
    "## Capture a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dc59e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing some face recognisation with the webcam\n",
    "\n",
    "import cv2\n",
    "video=cv2.VideoCapture(0)   #0-webcam\n",
    "\n",
    "while True:\n",
    "    num,frame=video.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('Video',frame)\n",
    "    if cv2.waitKey(1)==ord('q'):   # if we click q then only video closes\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91eefd",
   "metadata": {},
   "source": [
    "## Face & Eye Detection using HAAR Cascade Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ede8ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "eye_cascade=cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "def detect(gray,frame):\n",
    "    faces=face_cascade.detectMultiScale(gray,1.05,5)\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_color=resized_image[y:y+h,x:x+w]\n",
    "        eyes=eye_cascade.detectMultiScale(roi_gray,1.05,3)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    return frame\n",
    "\n",
    "#Doing some face recognisation with the webcam\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    check,frame=video.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    canvas=detect(gray,frame)\n",
    "    cv2.imshow('Video',canvas)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b407b",
   "metadata": {},
   "source": [
    "## Pedistrian Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7855882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#Create our body classifier\n",
    "body_classifier=cv2.CascadeClassifier('Haarcascades/haarcascade_fullbody.xml')\n",
    "\n",
    "#Initiate video capture for video file\n",
    "cap=cv2.VideoCapture('image_examples\\walking.avi')\n",
    "\n",
    "while cap.isOpened():\n",
    "    check,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    bodies=body_classifier.detectMultiScale(gray,1.2,4) #Zoom\n",
    "    #(filename,zoom,no.of nearest neighbors)\n",
    "    \n",
    "    #Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h)in bodies:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        #That shows rectangle on image in each frame of the video\n",
    "        cv2.imshow('Pedestrians',frame)\n",
    "        \n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66ed2c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#Create our body classifier\n",
    "car_classifier=cv2.CascadeClassifier('Haarcascades/haarcascade_car.xml')\n",
    "\n",
    "#Initiate video capture for video file\n",
    "cap=cv2.VideoCapture('image_examples\\car.avi')\n",
    "\n",
    "#Loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    time.sleep(.01)\n",
    "    #Read first frame\n",
    "    check,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    cars=car_classifier.detectMultiScale(gray,1.4,2)\n",
    "    \n",
    "    #Extract bounding boxes for any bodies identified\n",
    "    for(x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cv2.imshow('Cars',frame)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fca2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
